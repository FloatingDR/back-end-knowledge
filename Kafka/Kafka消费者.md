# 1. 消费者和消费者群组

kafka消费者从属于消费者群组。一个群组里的消费者订阅的是同一个主题，每个消费者接收主题的一部分分区的消息。

**消费者群组和分区再平衡**

分区的所有权从一个消费者转移到另一个消费者，这样的行为被称为**再平衡**。再平衡非常重要，它为消费者群组带来了高可用和伸缩性（可以放心地添加或移除消费者），不过在再平衡期间，消费者无法读取消息，造成整个群组一小段时间的不可用。另外当分区被重分配给另一个消费者时，消费者当前的读取状态会丢失，它有可能还需要去刷缓存，在它重新恢复状态之前会拖慢应用程序。

消费者通过向北指派为**群组协调器**的 broker（不同的群组可以有不同的协调器）发送**心跳**来维持它们和群组的从属关系以及它们对分区的所有权关系。只要消费者以正常的时间间隔发送心跳，就被认为是活跃的，说明它还在读取分区里的消息。消费者会在轮询消息（为了获取消息）或提交偏移量时发送心跳。如果消费者停止发送心跳的时间足够长，会话就会过期，群组协调器认为它已经死亡，就会触发一次再平衡。

如果一个消费者发送崩溃，并停止读取消息，群组协调器会等待几秒钟，确认它死亡了才会触发再平衡。在这几秒种时间里，死掉的消费者不会读取分区里的消息。在清理消费者时，消费者会通知协调器它将要离开群组，协调器会立即出发一次再平衡，尽量降低处理停顿。

> **心跳行为在最近版本中的变化**
>
> 在 0.10.1 版本里， Kafka 社区引入了一个独立的心跳线程，可以在轮均消息的空档发 送心跳 。 这样一来，发送心跳的频率(也就是消费者群纽用于检测发生崩溃的消费者或不再发送心跳的消费者 的 时间)与消息轮询的频率(由处理消息所花费的时间未确 定)之间就是相互独立的 。 在新版本的 Kafka 里，可以指定消费者在离开群纽并触发 再均衡之前可以有多长时间不进行消息轮询，这样可以避免出现活锁 (livelock)，比 如有时候应用程序并没有崩溃，只是由于某些原因导致无法正常运行 。 这个配直与 session.timeout.ms 是相互独立的，后者用于控制检测消费者发生崩溃的时间和 停 止 发送心跳的时间 。
>
> 本章的剩余部分将会讨论使 用 旧版本 Kafka 会面 i隘的一些问题，以及如何解决这些问 题。 本章还包括如何应对需妥较长时间来处理消息的情况的讨论，这些与 0.10.1 或史 高版本的 Kafka 没有太大关系 。 如果你使用的是较新版本的 Kafka，并且需要处理耗费较长时间的消息，只需妥加大 max.poll.interval.ms 的值未增加轮均间隔的时长。
>
> **分配分区是怎样的一个过程**
>
> 当消费者要加入群组时，它会向群组协调器发送一个 JoinGroup 请求。第一个加入群组的消费者将会成为“群主”。群主从协调器那里获得群组的成员列表（列表中包含了所有最近发送过心跳的消费者，它们被认为是活跃的），并负责给每个消费者分配分区。它使用一个实现了 PartitioinAssignor 接口的类来决定哪些分区应该被分配给哪个消费者。
>
> Kafka 内置了两种分配策略，分配完毕之后，群主把分配情况列表发送给群组协调器，协调器再把这些信息发送给所有的消费者。每个消费者只能看到自己的分配信息，只有群主知道群组里所有消费者的分配信息。这个过程会在每次重平衡时重复发生。

# 2. 创建Kafka消费者

三个必要的属性：bootstrap.servers、key.deserializer 和 value.deserializer

```java
ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
```

这个代码很重要，消费者必须持续对 Kafka 进行轮询，否则会被认为已经死亡，它的分区会移交给群组里其他消费者。传给 poll( ) 方法的参数是一个超时时间，用于控制 poll( ) 方法的阻塞时间（在消费者的缓冲区里没有可用数据时会发生阻塞）。如果该参数被设为0，poll( ) 方法会立即返回，否则它会在指定的毫秒数内一直等待 broker 返回数据。

在退出应用程序之前使用 close( ) 方法关闭消费者。网络连接和 socket 也会随之关闭，并立即触发一次再平衡，而不是等待群组协调器发现它不再发送心跳并认定它已死亡，因为那样需要更长的时间，导致整个群组在一段时间内无法读取消息。

**轮询不只是获取数据那么简单。在第一次调用新消费者的 poll( ) 方法时，它会负责查找 GroupCoordinator，然后加入群组，接受分配的分区。如果发生了再平衡，整个过程也是在轮询期间进行的。当然，心跳也是从轮询里发送出去的。所以要确保在轮询期间所做的任何处理工作都要应该尽快完成。**

# 3. 消费者的配置

**1. fetch.min.bytes**

该属性指定了消费者从服务器获取记录的最小字节数。broker 在收到消费者的数据请求时，如果可用的数据量小于 fetch.min.bytes 指定的大小，那么它会等到有足够的可用数据时才会把它返回给消费者。这样可以降低消费者和 broker 的工作负载，因为它们在主题不是很活跃的时候就不需要来来回回地处理消息。如果没有很多可用数据，但消费者的 CPU 使用率却很高，那么就需要把该属性的值设的比默认值大。如果消费者的数量很多，把该属性的值设的大一点可以降低 broker 的工作负载。

**2. fetch.max.wait.ms**

如果没有足够的数据流入 Kafka （fetch.min.bytes）用于指定 broker 的等待时间，默认时 500ms。

**3. max.partition.fetch.bytes**

该属性指定了服务器从每个分区里返回给消费者的最大字节数。它的默认值是 1MB，也就是说，KafkaConsumer.poll( ) 方法从每个分区里返回的记录最多不超过 max.partition.fetch.bytes 指定的字节。

**4. session.timeout.ms**

该属性指定了消费者在被认为死亡之前可以与服务器断开连接的十几斤，默认是 3s。

**5. auto.offset.reset**

该属性指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下（因消费者长时间失效，包含偏移量的几率已经过时并被删除）该作何处理。它的默认追是 latest，另一个值是 earliest。

**6. enable.auto.commint**

该属性指定了消费者是否自动提交偏移量，默认是 true。为了尽量避免出现重复数据和数据丢失，可以把它设为 false，由自己控制合适提交偏移量。如果可以把它设为 true，还可以通过 auto.commit.interval.ms 属性来控制提交的频率。

**7. partition.assignment.strategy**

分区会被分配给群组里的消费者。PartitionAssignor 根据给定的消费者和主题，决定哪些分区应该被分配给哪个消费者。Kafka 有两个默认的分配策略。

- Range：该策略会把主题的若干个连续的分区分配给消费者。假设悄费者 Cl 和消费者 C2 同时 订阅了主题 Tl 和主题 T2，井且每个主题有 3 个分区。那么消费者 Cl 有可能分配到过 两个主题的分区 0 和 分区 i，而消费者 C2 分配到这两个 主题 的分区 2。因为每个 主题 拥有奇数个分区，而分配是在主题内独立完成的，第一个消费者最后分配到比第二个消 费者更多的分区。只要使用了 Range策略，而且分区数量无怯被消费者数量整除，就会 出现这种情况。
- RoundRobin：该策略吧主题的所有分区分配给消费者。如果使用 RoundRobin 策略来给消费者 Cl 和消费者 C2分配分区，那么消费者 Cl 将分到主题 Tl 的分区 0和分区 2以及主题 T2 的分区 1，消费者 C2 将分配到主题 Tl 的分区 l 以及主题口的分区 0和分区 2。一般 来说，如果所有消费者都订阅相同的主题(这种情况很常见), RoundRobin策略会给所 有消费者分配相同数量 的分区(或最多就差一个分区)。

可以通过 partition.assignment.strategy 来选择分区策略。默认使用的是 org.apache.kafka.clients.consumer.RangeAssignor，这个类实现了 Range 策略，不过也可以改为 org.apache.kafka.cclients.consumer.RoundRobinAssignor。还可以自定义策略。

**8. client.id**

该属性可以是任意字符串，broker 用它来标识从客户端发送过来的消息，通常被用在日志、度量指标和配额里。

**9. max.poll.records**

该属性用于控制单次调用 call( ) 方法能够返回的记录数量，可以控制在轮询里需要处理的数据量。

**10. receive.buffer.bytes 和 send.buffer.bytes**

socket 在读写数据时用到的 TCP 缓冲区也可以设置大小。如果它们被设为 -1，就使用操作系统的默认值。

# 4. 提交偏移量

**1. 自动提交**

如果 enable.auto.commit 被设为 true，那么每过 5s，消费者会自动把从 poll( ) 方法接收到的最大偏移量提交上去。提交时间间隔由 auto.commit.interval.ms 控制，默认值是 5s。与消费者里的其他东西一样，自动提交也是在轮询里进行的。消费者每次在进行轮询时会检查是否该提交偏移量了，如果是，那么就会提交从上一次轮询返回的偏移量。

**2. 提交当前偏移量**

把 auto.commint.offset 设为 false，让应用程序决定何时提交偏移量。使用 commitSync( ) 提交偏移量最简单也最可靠。这个 API 会提交由 poll( ) 方法返回的最新偏移量，提交成功后马上返回，如果提交失败就会抛出异常。

**3. 异步提交**

手动提交有一个不足之处，在 broker 对提交请求作出回应之前，应用程序会一直阻塞，这样会限制应用程序的吞吐量。可以通过降低提交频率来提升吞吐量，但如果发生了重平衡，会增加重复消费的数量。

**4. 同步和异步组合提交**

```java
try {
    while (true) {
        // 如果拉到数据的话 会立即放回；如果拉不到数据的话，这个是最长的等待时间；
        // 比如5s，如果一直没有数据的话，每5s拉一次返回一次，有数据就立即返回再拉
        ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
        records.forEach(System.out::println);
        consumer.commitAsync();
    }
} catch (Exception e) {
    log.error("发生异常", e);
} finally {
    try {
        consumer.commitSync();
    }catch (Exception e){
        consumer.close();
    }
}
```

**5. 提交特定的偏移量**

```java
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    for (ConsumerRecord<String, String> record : records) {
        Map<TopicPartition, OffsetAndMetadata> offsets = new HashMap<>();
        offsets.put(new TopicPartition(record.topic(), record.partition()), new OffsetAndMetadata(record.offset() + 1));
        consumer.commitSync(offsets);
    }
}
```



