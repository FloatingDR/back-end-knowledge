# 1. 可靠性保证

Kafka 的保证：

- Kafka可以保证分区消息的顺序。如果使用同一个生产者往同一个分区写入消息，而且消息B在消息A之后写入，那么Kafka可以保证消息B的偏移量比消息A的偏移量大，而且消费者会先读取消息A再读取消息B。
- 只有点那个消息被写入分区的所有同步副本时（但不一定要写入磁盘），它才被认为是“已提交”的。生产者可以选择接收不同类型的确认，比如在消息被完全提交时的确认，或者在消息被写入首领副本时的确认，或者在消息被发送到网络时的确认。
- 只要还有一个副本时活跃的，那么已经提交的消息就不会丢失。
- 消费者只能读取已经提交的消息。

这些基本的保证机制可以用来构建可靠的系统，但仅仅依赖它们是无法保证系统完全可靠的。构建一个可靠的系统需要作出一些权衡，Kafka 管理员和开发者可以在配置参数上作出权衡，从而得到他们想要的可靠性。这种权衡一般是指小修存储的可靠性和一致性的重要程度与可用性、高吞吐量、低延迟和硬件成本的重要程度之间的权衡。

# 2. 复制

Kafka 的复制机制和多副本架构是 Kafka 可靠性保证的核心。把消息写入多个副本可以使 Kafka 在发生崩溃时仍能保证消息的持久性。

Kafka 的主题被分为多个分区，分区是基本的数据块。分区存储在单个磁盘上，Kafka 可以保证分区里的事件是有序的，分区可以在线（可用），也可以离线（不可用）。每个分区可以有多个副本，其中一个副本时首领。所有的事件都直接发送给首领副本，或者直接从首领副本读取事件。其他副本只需要与首领保持同步，并及时复制最新的事件。当首领副本不可用时，其中一个同步副本将成为新首领。

分区首领是同步副本，而对于跟随者副本来说，它需要满足以下条件才能认为是同步的：

- 与 Zookeeper 之间有一个活跃的会话，也就是说，它在过去的 6s（可配置）内向 Zookeeper 发送过心跳。
- 在过去的 10s 内（可配置）从首领那里获取过消息。
- 在过去的 10s 内从首领那里获取过最新的消息。光从首领那里获取消息是不够的，他还必须是几乎零延迟的。

如果跟随者副本不能满足以上任何一点，比如与 Zookeeper 断开连接，或者不再获取新消息，或者获取消息滞后了 10s 以上，那么它就被认为是不同步的。一个不同步的副本通过与 Zookeeper 重新建立连接，并从首领那里获取最新消息，可以重新变为同步的。这个过程在网络出现临时问题并很快得到修复的情况下会很快完成，但如果 broker 发生崩溃就需要较长的时间。

> **非同步副本**
>
> 如果一个或多个副本在同步和非同步状态之间快速切换，说明集群内部出现了问题。通常是 JAVA 不恰当的垃圾回收配置导致的。不恰当的垃圾回收配置会造成几秒钟的停顿，从而让 broker 与 zookeeper 之间断开连接，最后变成不同步的，进而发生状态切换。

一个滞后的同步副本会导致生产者和消费者变慢，因为在消息被认为已**提交**之前，客户端会等待所有同步副本接收消息。而如果一个副本不再同步了，就不再关系它是否已经收到消息。虽然非同步副本同样滞后，但它并不会对性能产生任何影响。淡水，更少的同步副本意味着有更低的有效复制系数，在发生宕机时丢水数据的风险更大。

# 3. broker配置

broker 有 3 个配置参数会影响 Kafka 消息存储的可靠性。与其他配置参数一样，它们可以应用在 broker 级别，用于控制所有主题的行为，也可以应用在主题级别，用于控制个别主题的行为。

在主题级别控制可靠性，意味着 Kafka 集群可以同时拥有可靠的主题和非可靠的主题。

## 3.1 复制系数

主题级别的配置参数是 replication.factor，而在 broker 级别则可以通过 default.repliication.factor 来配置自动创建的主题。

副本的分布也很重要。默认情况下，Kafka 会确认分区的每个副本被放到不同的 broker 上。不过有时候这样仍然不够安全。如果这些 broker 处于同一个机架上，一旦机架的交换机发生故障，分区就会不可用，这个时候把复制系数设为多少都不管用。为了避免机架级别的故障，建议把 broker 分布在多个不同的机架上，并使用 broker.rak 参数来为每个 broker 配置所在机架的名字。如果配置了机架名字， Kafka 会保证分区的副本被分布在多个机架上，从而获得更高的可用性。

## 3.2 不完全的首领选举

unclean.leader.election 只能在 broker 级别（实际上是在集群范围内）进行配置，它的默认值是true。

当分区首领不可用时，一个同步副本会被选举为新首领。如果在选举过程中没有丢失数据，也就是说提交的数据同时存在于所有的同步副本上，那么这个选举就是“完全”的。

但如果在首领不可用时其他副本都是不同步的，该怎么办？

这种情况会在以下两种场景里出现：

- 分区有 3 个副本，其中的两个跟随者副本不可用（比如有两个 broker 发生崩溃）。这个时候，如果生产者继续往首领写入数据，所有消息都会得到确认并提交（因为此时首领是唯一的同步副本）。现在假设首领也不可用了，这个时候，如果之前的一个跟随者重新启动，它就成为了分区的唯一不同步副本。
- 分区有 3 个副本，因为网络问题导致两个跟随者副本复制消息滞后，所以尽管它们还在复制消息，但已经不同步了。首领作为唯一的同步副本继续接受消息。这个时候，如果首领变为不可用，另外两个副本就再也无法变成同步了。

对于这场景，需要作出一个两难的选择。

- 如果不同步的副本不能被提升为新首领，那么分区在旧首领（最后一个同步副本）恢复之前是不可用的。有时候这种状态会持续数小时（比如更换内存芯片）。
- 如果不同步的副本可以被提升为新首领，那么在这个副本变为不同步之后写入旧首领的小休会全部丢失，导致数据不一致。

**简而言之，如果允许不同步的副本成为首领，那么就要承担丢失数据和出现数据不一致的风险。如果不允许它们成为首领，那么就要接受较低的可用性，因为必须等待原先的首领恢复到可用状态。**

如果把 unclean.leader.election.enable 设为 true，就是允许不同步的副本成为首领（也就是不完全的选举），那么将面临丢失消息的风险。如果把这个参数设为 false，就要等待原先的首领重新上线，从而将对了可用性。

## 3.3 最少同步副本

在主题级别和 broker 级别上，这个参数都叫 min.insync.replicas。

尽管一个主题配置了几个副本，还是会穿线只有一个同步副本的情况，而如果这个同步副本变为不可用，这时就必须在可用性和一致性之间作出选择——这是一个两难的选择。根据 Kafka 对可靠性保证的定义，消息只有被写入到所有同步副本之后才被认为是已提交的。

如果要确保已提交的数据被写入不止一个副本，就需要把最少同步副本数量设置为大一点的值。对于一个包含 3 个副本的主题，如果 min.insync.replicas 被设为 2，那么至少要存在两个同步副本才能向分区写入数据。

如果 3个副本都是同步的，或者其中一个副本变为不可用，都不会有什么问题。不过，如 果有两个副本变为不可用，那么 broker就会停止接受生产者的请求。尝试发送数据的生产 者会收到 NotEnoughReplicasException异常。消费者仍然可以继续读取已有的数据。实际 上，如果使用这样的配置，那么当只剩下一个同步副本时，它就变成只读了，这是为了避 免在发生 不完全选举时数据的写入和读取出现非预期的行为。为了从只读状态中恢复，必须让两个不可用分区中的一个重新变为可用的(比如重启 broker)，并等待它变为同步的。

# 4. 在可靠的系统里使用生产

尽管将 broker 配置得很可靠，但如果没有对生产者进行可靠性方面的配置，这个那个系统仍然有可能出现突发性的数据丢失。

比如以下两个例子：

- 为 broker 配置了 3 个副本，井且禁用了不完全首领选举，这样应该可以保证万无一失。 我们把生产者发送消息的 acks设为 1 (只要首领接收到消息就可以认为消息写入成功)。 生产者发送一个消息给首领，首领成功 写入，但跟随者副本还没有接收到这个消息。 首 领向生产者发送了 一个响应，告诉它“消息写入成功”，然后它崩横了，而此时悄息还 没有被其他副本复制过去 。 另外两个副本此时仍然被认为是同步的(毕竟判定一个副本 不同步需要一小段时间)，而且其中的一个副本成了新的首领。 因为悄息还没有被写入这个副本，所以就丢失了，但发送消息的客户端却认为消息已成功 写入 。 因为消费者看 不到丢失的消息，所以此时的系统仍然是一致的(因为副本没有收到这个消息，所以 消 息不算已提交)，但从生产者角度来看，它丢失了 一个消息 。
- 为 broker 配置了 3 个副本，并且禁用了不完全首领选举。我们接受了之前的教训 ， 把 生产者的 acks设为 all。假设现在往 Kafka发送消息，分区的首领刚好崩愤，新的首领 正在选举当中， Kafka会向生产者返回“首领不可用”的响应。 在这个时候，如果生产者没能正确处理这个错误，也没有重试发送消息直到发送成功，那么消息也有可能丢失。 这算不上是 broker的可靠性问题，因为 broker并没有收到这个消息。这也不是一致性问题，因为消费者井没有读到这个消息。问题在于如果生产者没能正确处理这些错误， 弄丢消息的是它们自己。

那么如何避免这些悲剧性的后果呢？从上面两个例子可以看出，每个使用 Kafka 的开发人员都要注意两件事情：

- 根据可靠性需求配置恰当的 acks 值。
- 在参数配置和代码里正确处理错误。

## 4.1 发送确认

生产者可以选择以下 3 种不同的确认模式。

- acks = 0 意味着如果生产者能够通过网络把消息发送出去，那么就认为消息已成功写入 Kafka。在这种情况下还是有可能发生错误，比如发送的对象无法被序列化或者网卡发送故障，但如果是分区离线或整个集群长时间不可用，那就不会收到任何错误。即使是在发生完全首领选举的情况下，这种模式仍然会丢失消息，因为在新首领选举过程中它并不知道首领已经不可用了。在 acks=0 模式下的运行速度是非常快的（这就是为什么很多基准测试都是基于这个模式），你可以得到惊人的吞吐量和带宽利用率 ，不过如果选择了这种模式， 一定会丢失一些消息。
- acks = 1 意味着首领在收到消息并把它写入到分区数据文件（不一定同步到磁盘上）时会返回确认或错误响应。在这个模式下，如果发送正常的首领选举，生产者会在选举时收到一个 LeaderNotAvailableException 异常，如果生产者能恰当地处理这个错误，它会重试发送消息，最终消息会安全到达新的首领那里。不过在这个模式下仍然有可能丢失数据，比如消息已经成功写入首领，但在消息被复制到跟随者副本之前首领发生崩溃。
- acks = all 意味着首领在返回确认或错误响应之前，会等待所有同步副本都收到消息。如果和 min.insync.replicas 参数结合起来，就可以决定在返回确认前至少有多少个副本能够收到消息，这是最保险的做法——生产者互会一直重试直到消息被成功提交。不过这也是最慢的做法，生产者在继续发送其他消息之前需要等待所有副本都收到当前的消息。可以通过使用异步模式和更大的批次来加快速度，但这样做通常会降低吞吐量。

## 4.2 配置生产者的重试参数

生产者需要手动处理的错误包括两部分：一部分是生产者可以自动处理的错误，还有一部分是需要开发者手动处理的错误。

如果 broker 返回的错误可以通过**重试**来解决，那么生产者会自动处理这些错误。生产者向 broker 发送消息时， broker 可以返回一个成功的响应码或者一个错误的响应码。错误的响应码可以分为两种，一种是在重试之后可以解决的，还有一种是无法通过重试解决的。例如，如果 broker 返回的是 LEADER_NOT_AVAILABLE 错误，生产者可以尝试发送消息，也许这个时候一个新的首领被选举出来了，那么这次发送就会成功。另一方面，如果 broker 返回的是 INVALID_CONFIG 错误，即使通过重试也无法改变配置选项，所以这样的重试是没有意义的。这种错误是不可重试错误。

一般情况下，如果你的目标是不丢失任何消息，那么最好让生产者在遇到可重试错误时 能够保持重试。为什么要这样?因为像首领选举或网络连接这类问题都可以在 几秒钟之 内得到解决，如果让生产者保持重试，你就不需要额外去处理这些问题了。经常会有人 问 :“为生产者配置多少重试次数比较好?”这个要看你在生产者放弃重试井抛出异常之后想做些什么。 如果你想抓住异常并再多重试几次，那么就可以把重试次数设置得多一点， 让生产者继续重试;如果你想直接丢弃消息，多次重试造成 的延迟已 经失去发送消息 的意义;如果你想把消息保存到某个地方然后回过头来再继续 处理，那就可以停止重试。 Kafka的跨数据中心复制工具(MirrorMaker，我们将在第 8章介绍)默认会进行无限制的 重试(例如 retries=MAX_INT。作为一个具有高可靠性的复制工具，它决不会丢失消息。

要注意，重试发送一个已经失败的消息会带来一些风险，如果两个消息都写入成功，会导致消息重复。例如，生产者因为网络问题没有收到 broker 确认，但实际上消息已经写入成功，生产者会认为网络出现了临时故障，就重试发送该消息，这种情况下，broker 会收到两个相同的消息。重试和恰当的错误处理可以保证每个消息“至少被保存一次”，但 Kafka（**0.10.0 版本**） 无法保证每个消息“只被保存一次”，也就是**无法保证幂等性**。

## 4.3 额外的错误处理

使用生产者内置的重试机制可以在不造成消息丢失的情况下轻松地处理大部分错误，不过对于开发人员来说，仍然需要处理其他类型的错误，包括：

- 不可重试的 broker 错误，例如消息大小错误、认证错误等；
- 在消息发送之前发送的错误，例如序列化错误；
- 在生产者达到重试次数上限时或者在消息占用的内存达到上限时发生的错误。

# 5. 在可靠的系统里使用消费者

**如果消费者提交了偏移量却未能处理完消息，那么就有可能造成消息丢失，这是消费者丢失消息的主要原因。**这种情况下，如果其他消费者接手了工作，那些没有被处理完的消息就会被忽略，永远得不到处理，这就是为什么需要非常重视偏移量提交的时间点和提交的方式。

## 5.1 消费者的可靠性配置

- group.id：如果希望消费者可以看到主题的所有消息，那么需要为它们设置唯一的 group.id。
- auto.offset.reset：这个参数指定了在没有偏移量可提交时或者请求的偏移量在 broker 上不存在时，消费者会做什么，一种是 earliest，另一种是 lateest。
- enable.autot.commit：自动提交的主要缺点是，无法控制重复处理消息（比如消费者在自动提交偏移量之前停止处理消息），而且如果把消息交给另一个后台线程去处理，自动提交机制可能会在消息还没有处理完毕就提交偏移量。
- auto.commit.interval.ms：与自动提交有直接的关系。

## 5.2 显式提交偏移量

1. 总是在处理完成事件后再提交偏移量
2. 提交频率是性能和重复消息数量之间的权衡
3. 确保对提交的偏移量心里有数
4. 再平衡
5. 消费者可能需要重试
6. 消费者可能需要维护状态
7. 长时间处理
8. 仅一次传递

